{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import corect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = corect.utils.get_logger()\n",
    "\n",
    "def load_pkl(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/USER/aisafe_back\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "# parent_directory = os.path.dirname(current_directory)\n",
    "# os.chdir(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/USER/aisafe_back/.pixi/envs/default/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 108/108 [05:36<00:00,  3.11s/it]\n",
      "dev: 100%|██████████| 12/12 [00:37<00:00,  3.10s/it]\n",
      "test: 100%|██████████| 31/31 [02:11<00:00,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/29/2024 11:49:43 train vids:\n",
      "09/29/2024 11:49:43 ['Ses01F_impro01', 'Ses01F_impro02', 'Ses01F_impro03', 'Ses01F_impro04', 'Ses01F_impro05', 'Ses01F_impro06', 'Ses01F_impro07', 'Ses01F_script01_1', 'Ses01F_script01_2', 'Ses01F_script01_3', 'Ses01F_script02_1', 'Ses01F_script02_2', 'Ses01F_script03_1', 'Ses01F_script03_2', 'Ses01M_impro01', 'Ses01M_impro02', 'Ses01M_impro04', 'Ses01M_impro05', 'Ses01M_impro06', 'Ses01M_impro07', 'Ses01M_script01_1', 'Ses01M_script01_2', 'Ses01M_script01_3', 'Ses01M_script02_1', 'Ses01M_script03_1', 'Ses01M_script03_2', 'Ses02F_impro01', 'Ses02F_impro02', 'Ses02F_impro03', 'Ses02F_impro04', 'Ses02F_impro05', 'Ses02F_impro06', 'Ses02F_impro07', 'Ses02F_impro08', 'Ses02F_script01_2', 'Ses02F_script02_1', 'Ses02F_script02_2', 'Ses02F_script03_1', 'Ses02F_script03_2', 'Ses02M_impro01', 'Ses02M_impro03', 'Ses02M_impro04', 'Ses02M_impro05', 'Ses02M_impro06', 'Ses02M_script01_1', 'Ses02M_script01_2', 'Ses02M_script01_3', 'Ses02M_script02_1', 'Ses02M_script03_1', 'Ses02M_script03_2', 'Ses03F_impro01', 'Ses03F_impro02', 'Ses03F_impro03', 'Ses03F_impro04', 'Ses03F_impro05', 'Ses03F_impro06', 'Ses03F_impro07', 'Ses03F_impro08', 'Ses03F_script01_1', 'Ses03F_script01_2', 'Ses03F_script01_3', 'Ses03F_script02_1', 'Ses03F_script02_2', 'Ses03F_script03_2', 'Ses03M_impro01', 'Ses03M_impro02', 'Ses03M_impro03', 'Ses03M_impro04', 'Ses03M_impro05a', 'Ses03M_impro06', 'Ses03M_impro07', 'Ses03M_impro08a', 'Ses03M_impro08b', 'Ses03M_script01_1', 'Ses03M_script01_2', 'Ses03M_script01_3', 'Ses03M_script02_1', 'Ses03M_script02_2', 'Ses03M_script03_1', 'Ses03M_script03_2', 'Ses04F_impro01', 'Ses04F_impro02', 'Ses04F_impro03', 'Ses04F_impro04', 'Ses04F_impro05', 'Ses04F_impro06', 'Ses04F_impro08', 'Ses04F_script01_2', 'Ses04F_script01_3', 'Ses04F_script02_1', 'Ses04F_script02_2', 'Ses04F_script03_1', 'Ses04F_script03_2', 'Ses04M_impro01', 'Ses04M_impro02', 'Ses04M_impro03', 'Ses04M_impro04', 'Ses04M_impro05', 'Ses04M_impro06', 'Ses04M_impro07', 'Ses04M_impro08', 'Ses04M_script01_1', 'Ses04M_script01_2', 'Ses04M_script01_3', 'Ses04M_script02_1', 'Ses04M_script02_2', 'Ses04M_script03_1', 'Ses04M_script03_2']\n",
      "09/29/2024 11:49:43 dev vids:\n",
      "09/29/2024 11:49:43 ['Ses01M_impro03', 'Ses01M_script02_2', 'Ses02F_script01_1', 'Ses02F_script01_3', 'Ses02M_impro02', 'Ses02M_impro07', 'Ses02M_impro08', 'Ses02M_script02_2', 'Ses03F_script03_1', 'Ses03M_impro05b', 'Ses04F_impro07', 'Ses04F_script01_1']\n",
      "09/29/2024 11:49:43 test vids:\n",
      "09/29/2024 11:49:43 ['Ses05F_impro01', 'Ses05F_impro02', 'Ses05F_impro03', 'Ses05F_impro04', 'Ses05F_impro05', 'Ses05F_impro06', 'Ses05F_impro07', 'Ses05F_impro08', 'Ses05F_script01_1', 'Ses05F_script01_2', 'Ses05F_script01_3', 'Ses05F_script02_1', 'Ses05F_script02_2', 'Ses05F_script03_1', 'Ses05F_script03_2', 'Ses05M_impro01', 'Ses05M_impro02', 'Ses05M_impro03', 'Ses05M_impro04', 'Ses05M_impro05', 'Ses05M_impro06', 'Ses05M_impro07', 'Ses05M_impro08', 'Ses05M_script01_1', 'Ses05M_script01_1b', 'Ses05M_script01_2', 'Ses05M_script01_3', 'Ses05M_script02_1', 'Ses05M_script02_2', 'Ses05M_script03_1', 'Ses05M_script03_2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import corect\n",
    "\n",
    "\n",
    "log = corect.utils.get_logger()\n",
    "sbert_model = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")\n",
    "\n",
    "corect.utils.set_seed(900)\n",
    "\n",
    "\n",
    "(\n",
    "    video_ids,\n",
    "    video_speakers,\n",
    "    video_labels,\n",
    "    video_text,\n",
    "    video_audio,\n",
    "    video_visual,\n",
    "    video_sentence,\n",
    "    trainVids,\n",
    "    test_vids,\n",
    ") = pickle.load(\n",
    "    open(\"models/corect_feat_iemocap.pkl\", \"rb\"), encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "train, dev, test = [], [], []\n",
    "dev_size = int(len(trainVids) * 0.1)\n",
    "train_vids, dev_vids = trainVids[dev_size:], trainVids[:dev_size]\n",
    "\n",
    "for vid in tqdm(train_vids, desc=\"train\"):\n",
    "    train.append(\n",
    "        {\n",
    "            \"vid\" : vid,\n",
    "            \"speakers\" : video_speakers[vid],\n",
    "            \"labels\" : video_labels[vid],\n",
    "            \"audio\" : video_audio[vid],\n",
    "            \"visual\" : video_visual[vid],\n",
    "            \"text\": sbert_model.encode(video_sentence[vid]),\n",
    "            \"sentence\" : video_sentence[vid],\n",
    "        }\n",
    "    )\n",
    "for vid in tqdm(dev_vids, desc=\"dev\"):\n",
    "    dev.append(\n",
    "        {\n",
    "            \"vid\" : vid,\n",
    "            \"speakers\" : video_speakers[vid],\n",
    "            \"labels\" : video_labels[vid],\n",
    "            \"audio\" : video_audio[vid],\n",
    "            \"visual\" : video_visual[vid],\n",
    "            \"text\": sbert_model.encode(video_sentence[vid]),\n",
    "            \"sentence\" : video_sentence[vid],\n",
    "        }\n",
    "    )\n",
    "for vid in tqdm(test_vids, desc=\"test\"):\n",
    "    test.append(\n",
    "        {\n",
    "            \"vid\" : vid,\n",
    "            \"speakers\" : video_speakers[vid],\n",
    "            \"labels\" : video_labels[vid],\n",
    "            \"audio\" : video_audio[vid],\n",
    "            \"visual\" : video_visual[vid],\n",
    "            \"text\": sbert_model.encode(video_sentence[vid]),\n",
    "            \"sentence\" : video_sentence[vid],\n",
    "        }\n",
    "    )\n",
    "\n",
    "log.info(\"train vids:\")\n",
    "log.info(sorted(train_vids))\n",
    "log.info(\"dev vids:\")\n",
    "log.info(sorted(dev_vids))\n",
    "log.info(\"test vids:\")\n",
    "log.info(sorted(test_vids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, Optimizer\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import corect\n",
    "\n",
    "log = corect.utils.get_logger()\n",
    "data = load_pkl(f\"model/corect_data_iemocap.pkl\")\n",
    "\n",
    "trainset = corect.Dataset(data[\"train\"], args)\n",
    "devset = corect.Dataset(data[\"dev\"], args)\n",
    "testset = corect.Dataset(data[\"test\"], args)\n",
    "\n",
    "log.debug(\"Building model...\")\n",
    "    \n",
    "    model_file = args.data_root + \"/model_checkpoints/model.pt\"\n",
    "    model = corect.CORECT(args).to(args.device)\n",
    "    opt = corect.Optim(args.learning_rate, args.max_grad_value, args.weight_decay)\n",
    "    opt.set_parameters(model.parameters(), args.optimizer)\n",
    "    sched = opt.get_scheduler(args.scheduler)\n",
    "\n",
    "    coach = corect.Coach(trainset, devset, testset, model, opt, sched, args)\n",
    "    if not args.from_begin:\n",
    "        ckpt = torch.load(model_file)\n",
    "        coach.load_ckpt(ckpt)\n",
    "        print(\"Training from checkpoint...\")\n",
    "\n",
    "    # Train\n",
    "    log.info(\"Start training...\")\n",
    "    ret = coach.train()\n",
    "\n",
    "    # Save.\n",
    "    checkpoint = {\n",
    "        \"best_dev_f1\": ret[0],\n",
    "        \"best_epoch\": ret[1],\n",
    "        \"best_state\": ret[2],\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = load_pkl(f\"model/corect_data_iemocap.pkl\")\n",
    "    model_dict = torch.load(\n",
    "        \"models/model_checkpoints/\"\n",
    "        + \"MELD\"\n",
    "        + \"_best_dev_f1_model_\"\n",
    "        + \"atv\"\n",
    "        + \".pt\",\n",
    "    )\n",
    "    stored_args = model_dict[\"args\"]\n",
    "    model = model_dict[\"state_dict\"]\n",
    "    testset = corect.Dataset(data[\"test\"], stored_args)\n",
    "\n",
    "    test = True\n",
    "    with torch.no_grad():\n",
    "        golds = []\n",
    "        preds = []\n",
    "        for idx in tqdm(range(len(testset)), desc=\"test\" if test else \"dev\"):\n",
    "            data = testset[idx]\n",
    "            golds.append(data[\"label_tensor\"])\n",
    "            for k, v in data.items():\n",
    "                if not k == \"utterance_texts\":\n",
    "                    data[k] = v.to(stored_args.device)\n",
    "            y_hat = model(data)\n",
    "\n",
    "            preds.append(y_hat.detach().to(\"cpu\"))\n",
    "\n",
    "        golds = torch.cat(golds, dim=-1).numpy()\n",
    "        preds = torch.cat(preds, dim=-1).numpy()\n",
    "        f1 = metrics.f1_score(golds, preds, average=\"weighted\")\n",
    "\n",
    "        if test:\n",
    "            print(metrics.classification_report(golds, preds, digits=4))\n",
    "            print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
